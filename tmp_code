# Identify continuous columns
continuous_cols <- sapply(df, is.numeric)

# Scale only the continuous columns
scaled_continuous <- scale(df[, continuous_cols])

# Convert the scaled matrix back to a data frame
scaled_continuous <- as.data.frame(scaled_continuous)

# Rename the scaled columns
colnames(scaled_continuous) <- paste0("scaled_", colnames(df)[continuous_cols])

# Combine scaled continuous columns with original categorical columns
final_df <- cbind(scaled_continuous, df[, !continuous_cols, drop = FALSE])



library(caret)
library(class)

# Assuming 'df' is your pre-scaled data frame and 'attrition' is the target variable
set.seed(123)  # For reproducibility

# Function to calculate metrics
calculate_metrics <- function(confusion_mat) {
  accuracy <- sum(diag(confusion_mat)) / sum(confusion_mat)
  sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
  specificity <- confusion_mat[1, 1] / sum(confusion_mat[1, ])
  return(c(accuracy = accuracy, sensitivity = sensitivity, specificity = specificity))
}

# Initialize results storage
results <- data.frame(variable = character(),
                      k_value = integer(),
                      accuracy = numeric(),
                      sensitivity = numeric(),
                      specificity = numeric(),
                      stringsAsFactors = FALSE)

# Loop through each continuous column
for (var in colnames(df)[sapply(df, is.numeric)]) {
  
  # Perform Leave-One-Out Cross-Validation
  for (k in 1:50) {
    predictions <- character(nrow(df))
    
    for (i in 1:nrow(df)) {
      # Create training and test sets
      train_data <- df[-i, ]
      test_data <- df[i, , drop = FALSE]
      
      # Predict using k-NN
      predictions[i] <- knn(train = train_data[, var, drop = FALSE],
                             test = test_data[, var, drop = FALSE],
                             cl = train_data$attrition,
                             k = k)
    }
    
    # Create confusion matrix
    confusion_mat <- table(predictions, df$attrition)
    
    # Calculate metrics
    metrics <- calculate_metrics(confusion_mat)
    
    # Store results
    results <- rbind(results, data.frame(variable = var,
                                          k_value = k,
                                          accuracy = metrics['accuracy'],
                                          sensitivity = metrics['sensitivity'],
                                          specificity = metrics['specificity']))
  }
}

# Find top three variables based on accuracy
top_results <- results[order(-results$accuracy), ]
top_three <- head(top_results, 3)

# Display the top three variables and their best k
print(top_three)
